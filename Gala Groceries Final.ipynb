{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNEbAM_fTXi4",
        "outputId": "ac1b71f2-f6dc-417f-c4ea-232e77b020ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary modules\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "vaE0axAVTozC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SPLIT=0.8\n",
        "PATH = \"/content/drive/MyDrive/Cognizant/Task 2/\"\n",
        "K = 10"
      ],
      "metadata": {
        "id": "2FPqdvdnVUsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load data from path\n",
        "def load_data(tablename):\n",
        "    df = pd.read_csv(PATH+tablename)\n",
        "    df.drop(columns=[\"Unnamed: 0\"], inplace=True, errors='ignore')\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "sCOtIZv3T6RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split dependent and independent variables\n",
        "def split_columns(data: pd.DataFrame):\n",
        "    # Check to see if the target variable is present in the data\n",
        "    if \"estimated_stock_pct\" not in data.columns:\n",
        "        raise Exception(f\"Target: estimated_stock_pct is not present in the data\")\n",
        "\n",
        "    X = data.drop(columns=[\"estimated_stock_pct\"])\n",
        "    y = data[\"estimated_stock_pct\"]\n",
        "    return X, y\n",
        "\n"
      ],
      "metadata": {
        "id": "e3xnLN0iT_De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train using cross validation\n",
        "def train(X: pd.DataFrame, y: pd.Series):\n",
        "\n",
        "    # Create a list that will store the accuracies of each fold\n",
        "    accuracy = []\n",
        "\n",
        "    # Enter a loop to run K folds of cross-validation\n",
        "    for fold in range(0, K):\n",
        "\n",
        "        # Instantiate algorithm and scaler\n",
        "        model = RandomForestRegressor()\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        # Create training and test samples\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=SPLIT, random_state=42)\n",
        "\n",
        "        # Scale X data, we scale the data because it helps the algorithm to converge\n",
        "        # and helps the algorithm to not be greedy with large values\n",
        "        scaler.fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Train model\n",
        "        trained_model = model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate predictions on test sample\n",
        "        y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Compute accuracy, using mean absolute error\n",
        "        mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "        accuracy.append(mae)\n",
        "        print(f\"Fold {fold + 1}: MAE = {mae:.3f}\")\n",
        "\n",
        "    # Finish by computing the average MAE across all folds\n",
        "    print(f\"Average MAE: {(sum(accuracy) / len(accuracy)):.2f}\")"
      ],
      "metadata": {
        "id": "9eace50BUCIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting TimeStamp to Date Time Format and Hourly\n",
        "def preprocess_timestamp(df: pd.DataFrame):\n",
        "  df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y-%m-%d %H:%M:%S')\n",
        "  dummy = df.copy()\n",
        "  new_ts = dummy[\"timestamp\"].tolist()\n",
        "  new_ts = [i.strftime('%Y-%m-%d %H:00:00') for i in new_ts]\n",
        "  new_ts = [datetime.strptime(i, '%Y-%m-%d %H:00:00') for i in new_ts]\n",
        "  dummy[\"timestamp\"] = new_ts\n",
        "  return dummy"
      ],
      "metadata": {
        "id": "OrHfMnTKUE2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Aggregation based on timestamp and product id\n",
        "def aggregate(df: pd.DataFrame, tablename: str):\n",
        "\n",
        "  if tablename ==\"sales\":\n",
        "    sales_agg = df.groupby(['timestamp', 'product_id']).agg({'quantity': 'sum'}).reset_index()\n",
        "    return sales_agg\n",
        "\n",
        "  elif tablename == \"stock\":\n",
        "    stock_agg = df.groupby(['timestamp', 'product_id']).agg({'estimated_stock_pct': 'mean'}).reset_index()\n",
        "    return stock_agg\n",
        "\n",
        "  elif tablename == \"temp\":\n",
        "    temp_agg = df.groupby(['timestamp']).agg({'temperature': 'mean'}).reset_index()\n",
        "    return temp_agg\n",
        "  else:\n",
        "    print(\"Provide accurate table name. Empty DataFrame Returned.\")\n",
        "    return pd.DataFrame()"
      ],
      "metadata": {
        "id": "9UuBz-GNXdXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merging DataFrames. Categories not included as they have least effect on the model\n",
        "# Only Timestamp Hour is used as it largely effects. Timestamp Day of week is also used. Day of Month is not used as\n",
        "# the importance of day of week and month is same\n",
        "def merge_dfs(sales_agg: pd.DataFrame, stock_agg: pd.DataFrame, temp_agg: pd.DataFrame,sales_df: pd.DataFrame):\n",
        "  merged_df = stock_agg.merge(sales_agg, on=['timestamp', 'product_id'], how='left')\n",
        "  merged_df = merged_df.merge(temp_agg, on='timestamp', how='left')\n",
        "  merged_df['quantity'] = merged_df['quantity'].fillna(0)\n",
        "\n",
        "  product_price = sales_df[['product_id', 'unit_price']]\n",
        "  product_price = product_price.drop_duplicates()\n",
        "  merged_df = merged_df.merge(product_price, on=\"product_id\", how=\"left\")\n",
        "  merged_df['timestamp_day_of_week'] = merged_df['timestamp'].dt.dayofweek\n",
        "  merged_df['timestamp_hour'] = merged_df['timestamp'].dt.hour\n",
        "  merged_df.drop(columns=['timestamp'], inplace=True)\n",
        "  merged_df.drop(columns=['product_id'], inplace=True)\n",
        "  return merged_df"
      ],
      "metadata": {
        "id": "BBwpad6kY9oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  # Data Loading\n",
        "  sales_df = load_data(\"sales.csv\")\n",
        "  stock_df = load_data(\"sensor_stock_levels.csv\")\n",
        "  temp_df = load_data(\"sensor_storage_temperature.csv\")\n",
        "  # Preprocessing\n",
        "  sales_df = preprocess_timestamp(sales_df)\n",
        "  stock_df = preprocess_timestamp(stock_df)\n",
        "  temp_df = preprocess_timestamp(temp_df)\n",
        "  # Aggregation\n",
        "  sales_agg = aggregate(sales_df, \"sales\")\n",
        "  stock_agg = aggregate(stock_df, \"stock\")\n",
        "  temp_agg = aggregate(temp_df, \"temp\")\n",
        "  # Merged Data Frame\n",
        "  merged_df = merge_dfs(sales_agg, stock_agg, temp_agg,sales_df)\n",
        "  # Splitting Dependent and Independent Columns\n",
        "  x,y = split_columns(merged_df)\n",
        "  # Training and Evaluation\n",
        "  train(x, y)\n"
      ],
      "metadata": {
        "id": "QpLETqAUbeSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbBNldvliMQ5",
        "outputId": "674ab2bf-aecb-4cce-d8eb-79198d8eab60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: MAE = 0.244\n",
            "Fold 2: MAE = 0.245\n",
            "Fold 3: MAE = 0.244\n",
            "Fold 4: MAE = 0.245\n",
            "Fold 5: MAE = 0.244\n",
            "Fold 6: MAE = 0.244\n",
            "Fold 7: MAE = 0.245\n",
            "Fold 8: MAE = 0.244\n",
            "Fold 9: MAE = 0.245\n",
            "Fold 10: MAE = 0.244\n",
            "Average MAE: 0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xd2-zR_qj7iE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}